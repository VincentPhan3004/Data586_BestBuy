{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA 586 PROJECT: BESTBUY - RECOMMENDATION SYSTEM\n",
    "\n",
    "### TEAM MEMBER:   CLAUDIA NIKEL - VINCENT PHAN\n",
    "\n",
    "Predict which Xbox game a visitor will be most interested in based on their search query\n",
    "https://www.kaggle.com/c/acm-sf-chapter-hackathon-small/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA DESCRIPTION  \n",
    "\n",
    "The main data for this competition is in the train.csv and test.csv files. These files contain information on what items users clicked on after making a search.\n",
    "\n",
    "Each line of train.csv describes a user's click on a single item. It contains the following fields:\n",
    "\n",
    "**user**: A user ID  \n",
    "**sku**: The stock-keeping unit (item) that the user clicked on   \n",
    "**category**: The category the sku belongs to  \n",
    "**query**: The search terms that the user entered  \n",
    "**click_time**: Time the sku was clicked on  \n",
    "**query_time**: Time the query was run \n",
    "\n",
    "test.csv contains all of the same fields as train.csv except for sku. It is your job to estimate which sku's were clicked on in these test queries. (Note: the label values for test data is not provided so we can not validate the accuracy of the model. Therefore, we will create test dataset and training data by the information from train.csv)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### METHODOLOGY\n",
    "\n",
    "Using a feedforward neutral network with a 776-output hidden layer and a 388-output layer to predict the sku of the observation. However to enhane the accuracy of the model, we use a pre-trained text embedding as the first layer, which will have advantages: benefit from transfer learning and the embedding has a fixed size, so it's simpler to process.This example we will use a pre-trained text embedding model from TensorFlow Hub called google/tf2-preview/gnews-swivel-20dim/1.\n",
    "\n",
    "We also go through the following step\n",
    "\n",
    "(Note : Step 1 and 2 below can skipped by loading the postpreprocessed dataset  in the code of step 3)\n",
    "\n",
    "1. Loading the data:   42365 queries  \n",
    "2. Preprocessing the query text (after this step the number of queries is 34199)  \n",
    "    - remove non-ASCII  \n",
    "    - remove punctuation  \n",
    "    - remove multiple characters occuring more than 2 times  \n",
    "    - remove non English query text  \n",
    "    - apply stemming to query text  \n",
    "3. Creating training and testing data set \n",
    "    - 80% for training\n",
    "    - 10% for validation\n",
    "    - 10% for testing\n",
    "4. Setting up neutral network \n",
    "5. Training and validate testing result\n",
    "\n",
    "The accuracy of the model with testing data is 92%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. LOADING THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42365, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>sku</th>\n",
       "      <th>category</th>\n",
       "      <th>query</th>\n",
       "      <th>click_time</th>\n",
       "      <th>query_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001cd0d10bbc585c9ba287c963e00873d4c0bfd</td>\n",
       "      <td>2032076</td>\n",
       "      <td>abcat0701002</td>\n",
       "      <td>gears of war</td>\n",
       "      <td>2011-10-09 17:22:56.101</td>\n",
       "      <td>2011-10-09 17:21:42.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00033dbced6acd3626c4b56ff5c55b8d69911681</td>\n",
       "      <td>9854804</td>\n",
       "      <td>abcat0701002</td>\n",
       "      <td>Gears of war</td>\n",
       "      <td>2011-09-25 13:35:42.198</td>\n",
       "      <td>2011-09-25 13:35:33.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00033dbced6acd3626c4b56ff5c55b8d69911681</td>\n",
       "      <td>2670133</td>\n",
       "      <td>abcat0701002</td>\n",
       "      <td>Gears of war</td>\n",
       "      <td>2011-09-25 13:36:08.668</td>\n",
       "      <td>2011-09-25 13:35:33.234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00033dbced6acd3626c4b56ff5c55b8d69911681</td>\n",
       "      <td>9984142</td>\n",
       "      <td>abcat0701002</td>\n",
       "      <td>Assassin creed</td>\n",
       "      <td>2011-09-25 13:37:23.709</td>\n",
       "      <td>2011-09-25 13:37:00.049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0007756f015345450f7be1df33695421466b7ce4</td>\n",
       "      <td>2541184</td>\n",
       "      <td>abcat0701002</td>\n",
       "      <td>dead island</td>\n",
       "      <td>2011-09-11 15:15:34.336</td>\n",
       "      <td>2011-09-11 15:15:26.206</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       user      sku      category  \\\n",
       "0  0001cd0d10bbc585c9ba287c963e00873d4c0bfd  2032076  abcat0701002   \n",
       "1  00033dbced6acd3626c4b56ff5c55b8d69911681  9854804  abcat0701002   \n",
       "2  00033dbced6acd3626c4b56ff5c55b8d69911681  2670133  abcat0701002   \n",
       "3  00033dbced6acd3626c4b56ff5c55b8d69911681  9984142  abcat0701002   \n",
       "4  0007756f015345450f7be1df33695421466b7ce4  2541184  abcat0701002   \n",
       "\n",
       "            query               click_time               query_time  \n",
       "0    gears of war  2011-10-09 17:22:56.101  2011-10-09 17:21:42.917  \n",
       "1    Gears of war  2011-09-25 13:35:42.198  2011-09-25 13:35:33.234  \n",
       "2    Gears of war  2011-09-25 13:36:08.668  2011-09-25 13:35:33.234  \n",
       "3  Assassin creed  2011-09-25 13:37:23.709  2011-09-25 13:37:00.049  \n",
       "4     dead island  2011-09-11 15:15:34.336  2011-09-11 15:15:26.206  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. PREPROCESSING WITH QUERY TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to string \n",
    "df['query_mod'] = df['query'].astype(str)\n",
    "# remove non-ASCII\n",
    "df['query_mod'] = df['query_mod'].str.replace('[^\\x00-\\x7F]','')\n",
    "# remove punctuation\n",
    "df['query_mod'] = df['query_mod'].str.replace('[{}]'.format(string.punctuation),'')\n",
    "# remove multiple characters occuring more than 2 times\n",
    "import re\n",
    "def replaceRepeat(x):\n",
    "    return re.sub(r'([a-z])\\1{2,}', r'\\1\\1', x)\n",
    "df['query_mod']= df['query_mod'].map(replaceRepeat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check non English words\n",
    "import langid as ld\n",
    "def enDect(x):\n",
    "    return ld.classify(x)[0] !='en'\n",
    "nonEn_index = df[df['query_mod'].map(enDect)==True].index.tolist()\n",
    "df=df.drop(nonEn_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying Stemming - basically removing the suffix from a word and reduce it to its root word\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "porter = PorterStemmer()\n",
    "#from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "def stemSentence(sentence):\n",
    "    token_words  = word_tokenize(sentence)\n",
    "    stem_sentence=[]\n",
    "    for word in token_words:\n",
    "        stem_sentence.append(porter.stem(word))\n",
    "        stem_sentence.append(\" \")\n",
    "    return \"\".join(stem_sentence)\n",
    "df['query_mod']= df['query_mod'].map(stemSentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(34199, 7)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"postprocessdata.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. CREATING TRAINING AND TESTING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "#!pip install -q tensorflow-hub\n",
    "#!pip install -q tfds-nightly\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds\n",
    "import pandas as pd\n",
    "import string\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not loading the \"postprocessdata.csv\" please unhidden this cell\n",
    "#df2 = pd.concat([df.query_mod, df.sku], axis=1)\n",
    "#df2.columns = ['feature', 'label']\n",
    "#dftf = tf.data.Dataset.from_tensor_slices((df2.feature, df2.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 =pd.read_csv(\"postprocessdata.csv\",header=0)\n",
    "df2 =pd.concat([df2.feature, df2.label], axis=1)\n",
    "df2['feature'] = df2['feature'].astype(str)\n",
    "dftf = tf.data.Dataset.from_tensor_slices((df2.feature, df2.label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * len(df2))\n",
    "val_size   = int(0.1*len(df2))\n",
    "test_size  = int(0.1 * len(df2))\n",
    "train_dataset = dftf.take(train_size)\n",
    "test_dataset  = dftf.skip(train_size)\n",
    "val_dataset   = dftf.skip(test_size)\n",
    "test_dataset  = dftf.take(test_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4 SETUP NEUTRAL NETWORK MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 20)                400020    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 776)               16296     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 388)               301476    \n",
      "=================================================================\n",
      "Total params: 717,792\n",
      "Trainable params: 717,792\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Determining number of output\n",
    "output_number=len(df2.label.unique())\n",
    "\n",
    "# Represent the text is to convert sentences into embeddings vector, \n",
    "# using a pre-trained text embedding model from TensorFlow Hub\n",
    "embedding = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
    "hub_layer = hub.KerasLayer(embedding, input_shape=[], \n",
    "                           dtype=tf.string, trainable=True)\n",
    "\n",
    "NNmodel = tf.keras.Sequential()\n",
    "NNmodel.add(hub_layer)\n",
    "NNmodel.add(tf.keras.layers.Dense(output_number*2, activation='relu'))\n",
    "NNmodel.add(tf.keras.layers.Dense(output_number,activation='sigmoid' ))\n",
    "NNmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting an optimizer and a loss function\n",
    "NNmodel.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=1e-1), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. TRAINNING NN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train for 137 steps, validate for 154 steps\n",
      "Epoch 1/20\n",
      "137/137 [==============================] - ETA: 2s - loss: 8778687488.0000 - accuracy: 0.945 - ETA: 1s - loss: 8883770624.0000 - accuracy: 0.920 - ETA: 1s - loss: 8804013847.2727 - accuracy: 0.909 - ETA: 1s - loss: 8871860128.0000 - accuracy: 0.913 - ETA: 1s - loss: 8935767575.2727 - accuracy: 0.915 - ETA: 1s - loss: 8958204397.0370 - accuracy: 0.915 - ETA: 1s - loss: 9003174508.6061 - accuracy: 0.914 - ETA: 1s - loss: 2964984558559297.5000 - accuracy: 0.916 - ETA: 0s - loss: 2628055504445091.0000 - accuracy: 0.915 - ETA: 0s - loss: 2312689900148644.0000 - accuracy: 0.916 - ETA: 0s - loss: 2102446231719759.2500 - accuracy: 0.915 - ETA: 0s - loss: 1895649127027737.2500 - accuracy: 0.916 - ETA: 0s - loss: 1752040033597199.5000 - accuracy: 0.915 - ETA: 0s - loss: 1606037439623018.7500 - accuracy: 0.915 - ETA: 0s - loss: 1482496748544302.0000 - accuracy: 0.915 - ETA: 0s - loss: 1376604775347126.7500 - accuracy: 0.915 - ETA: 0s - loss: 1284831725064368.2500 - accuracy: 0.915 - ETA: 0s - loss: 1204530297759930.7500 - accuracy: 0.916 - ETA: 0s - loss: 1133676117342785.2500 - accuracy: 0.916 - ETA: 0s - loss: 1070694605243444.1250 - accuracy: 0.915 - ETA: 0s - loss: 1014342738960325.6250 - accuracy: 0.915 - ETA: 0s - loss: 971723678639968.7500 - accuracy: 0.915 - ETA: 0s - loss: 925081367453687.7500 - accuracy: 0.91 - ETA: 0s - loss: 889501663056356.3750 - accuracy: 0.91 - ETA: 0s - loss: 856557496207128.6250 - accuracy: 0.91 - 2s 15ms/step - loss: 844062299392125.0000 - accuracy: 0.9154 - val_loss: 750879428660905.5000 - val_accuracy: 0.9160\n",
      "Epoch 2/20\n",
      "137/137 [==============================] - ETA: 3s - loss: 8778687488.0000 - accuracy: 0.950 - ETA: 1s - loss: 8893815442.2857 - accuracy: 0.918 - ETA: 1s - loss: 8833863040.0000 - accuracy: 0.911 - ETA: 1s - loss: 8918528873.4118 - accuracy: 0.914 - ETA: 1s - loss: 8952715642.4348 - accuracy: 0.915 - ETA: 1s - loss: 8950489051.4286 - accuracy: 0.916 - ETA: 1s - loss: 8999560342.5882 - accuracy: 0.915 - ETA: 0s - loss: 2890860155679398.5000 - accuracy: 0.917 - ETA: 0s - loss: 2513792618183324.0000 - accuracy: 0.915 - ETA: 0s - loss: 2223740639937053.5000 - accuracy: 0.916 - ETA: 0s - loss: 1993699489716983.2500 - accuracy: 0.916 - ETA: 0s - loss: 1806791000861528.0000 - accuracy: 0.915 - ETA: 0s - loss: 1651923962460942.7500 - accuracy: 0.915 - ETA: 0s - loss: 1521509617970560.0000 - accuracy: 0.915 - ETA: 0s - loss: 1427589799982914.2500 - accuracy: 0.916 - ETA: 0s - loss: 1344590911230243.7500 - accuracy: 0.916 - ETA: 0s - loss: 1270712793515733.7500 - accuracy: 0.916 - ETA: 0s - loss: 1192112556008495.5000 - accuracy: 0.916 - ETA: 0s - loss: 1122669642155549.8750 - accuracy: 0.916 - ETA: 0s - loss: 1070694605243453.6250 - accuracy: 0.916 - ETA: 0s - loss: 1014342738960334.6250 - accuracy: 0.916 - ETA: 0s - loss: 963626050910301.8750 - accuracy: 0.916 - ETA: 0s - loss: 917739522740451.5000 - accuracy: 0.91 - ETA: 0s - loss: 882711644652845.0000 - accuracy: 0.91 - 2s 14ms/step - loss: 844062299392125.0000 - accuracy: 0.9158 - val_loss: 750879428660992.0000 - val_accuracy: 0.9160\n",
      "Epoch 3/20\n",
      "137/137 [==============================] - ETA: 3s - loss: 8778687488.0000 - accuracy: 0.950 - ETA: 1s - loss: 8883770624.0000 - accuracy: 0.921 - ETA: 1s - loss: 8804013847.2727 - accuracy: 0.910 - ETA: 1s - loss: 8871860128.0000 - accuracy: 0.914 - ETA: 1s - loss: 8935767621.8182 - accuracy: 0.915 - ETA: 1s - loss: 8958204434.9630 - accuracy: 0.915 - ETA: 1s - loss: 8992137504.0000 - accuracy: 0.915 - ETA: 1s - loss: 8980324268.9730 - accuracy: 0.916 - ETA: 0s - loss: 2689172874669449.0000 - accuracy: 0.915 - ETA: 0s - loss: 2409051611079264.0000 - accuracy: 0.916 - ETA: 0s - loss: 2141380243935184.5000 - accuracy: 0.915 - ETA: 0s - loss: 1927243123696529.0000 - accuracy: 0.916 - ETA: 0s - loss: 1778994355107375.2500 - accuracy: 0.915 - ETA: 0s - loss: 1651923962460986.5000 - accuracy: 0.915 - ETA: 0s - loss: 1521509617970614.0000 - accuracy: 0.915 - ETA: 0s - loss: 1427589799982965.0000 - accuracy: 0.916 - ETA: 0s - loss: 1344590911230291.2500 - accuracy: 0.916 - ETA: 0s - loss: 1270712793515790.0000 - accuracy: 0.916 - ETA: 0s - loss: 1192112556008569.5000 - accuracy: 0.916 - ETA: 0s - loss: 1133676117342865.5000 - accuracy: 0.916 - ETA: 0s - loss: 1080701012543272.6250 - accuracy: 0.916 - ETA: 0s - loss: 1032455842542422.8750 - accuracy: 0.916 - ETA: 0s - loss: 979958545969711.7500 - accuracy: 0.915 - ETA: 0s - loss: 940123201691098.5000 - accuracy: 0.91 - ETA: 0s - loss: 903399989820648.0000 - accuracy: 0.91 - ETA: 0s - loss: 862949651608908.3750 - accuracy: 0.91 - 2s 15ms/step - loss: 844062299392192.2500 - accuracy: 0.9158 - val_loss: 750879428660992.0000 - val_accuracy: 0.9160\n",
      "Epoch 4/20\n",
      "137/137 [==============================] - ETA: 3s - loss: 8778687488.0000 - accuracy: 0.950 - ETA: 1s - loss: 8883770624.0000 - accuracy: 0.921 - ETA: 1s - loss: 8804013847.2727 - accuracy: 0.910 - ETA: 1s - loss: 8918528933.6471 - accuracy: 0.914 - ETA: 1s - loss: 8935767621.8182 - accuracy: 0.915 - ETA: 1s - loss: 8958204434.9630 - accuracy: 0.915 - ETA: 1s - loss: 8992137504.0000 - accuracy: 0.915 - ETA: 1s - loss: 8980324268.9730 - accuracy: 0.916 - ETA: 1s - loss: 2753200580638805.5000 - accuracy: 0.916 - ETA: 0s - loss: 2460307845024888.0000 - accuracy: 0.915 - ETA: 0s - loss: 2223740639937073.2500 - accuracy: 0.916 - ETA: 0s - loss: 1993699489717018.5000 - accuracy: 0.916 - ETA: 0s - loss: 1835470075885186.0000 - accuracy: 0.916 - ETA: 0s - loss: 1700509712527473.0000 - accuracy: 0.916 - ETA: 0s - loss: 1584037047729888.5000 - accuracy: 0.916 - ETA: 0s - loss: 1482496748544380.7500 - accuracy: 0.916 - ETA: 0s - loss: 1393190269861530.2500 - accuracy: 0.916 - ETA: 0s - loss: 1314032235033815.2500 - accuracy: 0.915 - ETA: 0s - loss: 1243385823512383.2500 - accuracy: 0.916 - ETA: 0s - loss: 1179948240489080.2500 - accuracy: 0.916 - ETA: 0s - loss: 1133676117342885.7500 - accuracy: 0.916 - ETA: 0s - loss: 1090896220569175.0000 - accuracy: 0.916 - ETA: 0s - loss: 1041757162465990.3750 - accuracy: 0.915 - ETA: 0s - loss: 996854224639514.5000 - accuracy: 0.916 - ETA: 0s - loss: 955662277716750.7500 - accuracy: 0.91 - ETA: 0s - loss: 917739522740536.8750 - accuracy: 0.91 - ETA: 0s - loss: 882711644652927.0000 - accuracy: 0.91 - ETA: 0s - loss: 850259342229293.1250 - accuracy: 0.91 - 2s 16ms/step - loss: 844062299392210.8750 - accuracy: 0.9160 - val_loss: 750879428661002.0000 - val_accuracy: 0.9163\n",
      "Epoch 5/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - ETA: 2s - loss: 8778687488.0000 - accuracy: 0.950 - ETA: 1s - loss: 8883770624.0000 - accuracy: 0.921 - ETA: 1s - loss: 8804013847.2727 - accuracy: 0.910 - ETA: 1s - loss: 8871860128.0000 - accuracy: 0.914 - ETA: 1s - loss: 8947017898.6667 - accuracy: 0.915 - ETA: 1s - loss: 8943047286.1538 - accuracy: 0.915 - ETA: 1s - loss: 8992137504.0000 - accuracy: 0.915 - ETA: 1s - loss: 8980324268.9730 - accuracy: 0.916 - ETA: 1s - loss: 2820351600235282.5000 - accuracy: 0.916 - ETA: 1s - loss: 2569654468882841.5000 - accuracy: 0.915 - ETA: 1s - loss: 2409051611079306.5000 - accuracy: 0.916 - ETA: 1s - loss: 2267343228398281.0000 - accuracy: 0.916 - ETA: 1s - loss: 2141380243935222.5000 - accuracy: 0.916 - ETA: 1s - loss: 2064902720216640.0000 - accuracy: 0.916 - ETA: 1s - loss: 1993699489717018.5000 - accuracy: 0.916 - ETA: 1s - loss: 1895649127027770.7500 - accuracy: 0.917 - ETA: 1s - loss: 1835470075885186.0000 - accuracy: 0.916 - ETA: 1s - loss: 1778994355107406.7500 - accuracy: 0.915 - ETA: 1s - loss: 1725890321765353.0000 - accuracy: 0.916 - ETA: 1s - loss: 1675864763202448.7500 - accuracy: 0.915 - ETA: 1s - loss: 1628657553666978.2500 - accuracy: 0.915 - ETA: 1s - loss: 1584037047729888.5000 - accuracy: 0.916 - ETA: 1s - loss: 1541796297475816.0000 - accuracy: 0.916 - ETA: 1s - loss: 1501749852353509.5000 - accuracy: 0.916 - ETA: 1s - loss: 1463731077244526.2500 - accuracy: 0.916 - ETA: 1s - loss: 1445434551121241.5000 - accuracy: 0.916 - ETA: 1s - loss: 1410180276393197.2500 - accuracy: 0.916 - ETA: 1s - loss: 1376604775347200.0000 - accuracy: 0.916 - ETA: 0s - loss: 1344590911230315.2500 - accuracy: 0.916 - ETA: 0s - loss: 1314032235033815.2500 - accuracy: 0.916 - ETA: 0s - loss: 1299267931528600.5000 - accuracy: 0.916 - ETA: 0s - loss: 1284831725064459.5000 - accuracy: 0.916 - ETA: 0s - loss: 1270712793515812.5000 - accuracy: 0.916 - ETA: 0s - loss: 1256900793012029.2500 - accuracy: 0.916 - ETA: 0s - loss: 1243385823512383.2500 - accuracy: 0.916 - ETA: 0s - loss: 1230158410963047.5000 - accuracy: 0.916 - ETA: 0s - loss: 1217209470926767.2500 - accuracy: 0.916 - ETA: 0s - loss: 1204530297760026.7500 - accuracy: 0.916 - ETA: 0s - loss: 1192112556008590.5000 - accuracy: 0.916 - ETA: 0s - loss: 1168029660067307.2500 - accuracy: 0.916 - ETA: 0s - loss: 1156349452001797.0000 - accuracy: 0.916 - ETA: 0s - loss: 1133676117342885.7500 - accuracy: 0.916 - ETA: 0s - loss: 1122669642155639.2500 - accuracy: 0.916 - ETA: 0s - loss: 1101285628710975.3750 - accuracy: 0.917 - ETA: 0s - loss: 1090896220569175.0000 - accuracy: 0.916 - ETA: 0s - loss: 1070694605243543.7500 - accuracy: 0.916 - ETA: 0s - loss: 1051227598426419.2500 - accuracy: 0.915 - ETA: 0s - loss: 1032455842542445.7500 - accuracy: 0.916 - ETA: 0s - loss: 1014342738960428.8750 - accuracy: 0.916 - ETA: 0s - loss: 996854224639514.5000 - accuracy: 0.916 - ETA: 0s - loss: 979958545969733.3750 - accuracy: 0.91 - ETA: 0s - loss: 963626050910391.5000 - accuracy: 0.91 - ETA: 0s - loss: 947829050625389.1250 - accuracy: 0.91 - ETA: 0s - loss: 932541630583391.0000 - accuracy: 0.91 - ETA: 0s - loss: 917739522740528.7500 - accuracy: 0.91 - ETA: 0s - loss: 910513304264030.7500 - accuracy: 0.91 - ETA: 0s - loss: 896396953225136.6250 - accuracy: 0.91 - ETA: 0s - loss: 882711644652919.2500 - accuracy: 0.91 - ETA: 0s - loss: 876024507275853.6250 - accuracy: 0.91 - ETA: 0s - loss: 869437929117226.3750 - accuracy: 0.91 - ETA: 0s - loss: 862949651608919.8750 - accuracy: 0.91 - ETA: 0s - loss: 856557496207208.2500 - accuracy: 0.91 - ETA: 0s - loss: 850259342229285.6250 - accuracy: 0.91 - 6s 42ms/step - loss: 844062299392203.3750 - accuracy: 0.9161 - val_loss: 750879428661012.0000 - val_accuracy: 0.9163\n",
      "Epoch 6/20\n",
      "137/137 [==============================] - ETA: 6s - loss: 8778687488.0000 - accuracy: 0.950 - ETA: 3s - loss: 8817522688.0000 - accuracy: 0.928 - ETA: 3s - loss: 8893815442.2857 - accuracy: 0.918 - ETA: 3s - loss: 8824931174.4000 - accuracy: 0.911 - ETA: 2s - loss: 8842821513.8462 - accuracy: 0.912 - ETA: 2s - loss: 8871860128.0000 - accuracy: 0.914 - ETA: 2s - loss: 8928949447.1111 - accuracy: 0.914 - ETA: 2s - loss: 8923734912.0000 - accuracy: 0.914 - ETA: 2s - loss: 8935767575.2727 - accuracy: 0.915 - ETA: 2s - loss: 8930005205.3333 - accuracy: 0.915 - ETA: 2s - loss: 8943047246.7692 - accuracy: 0.915 - ETA: 2s - loss: 8950489051.4286 - accuracy: 0.916 - ETA: 2s - loss: 8937542408.8276 - accuracy: 0.916 - ETA: 2s - loss: 8955268723.6129 - accuracy: 0.915 - ETA: 2s - loss: 9003174508.6061 - accuracy: 0.914 - ETA: 2s - loss: 8996459549.2571 - accuracy: 0.914 - ETA: 2s - loss: 8980324241.2973 - accuracy: 0.916 - ETA: 2s - loss: 2964984558559297.5000 - accuracy: 0.917 - ETA: 2s - loss: 2753200580638781.0000 - accuracy: 0.916 - ETA: 2s - loss: 2628055504445137.5000 - accuracy: 0.915 - ETA: 2s - loss: 2513792618183368.5000 - accuracy: 0.915 - ETA: 2s - loss: 2409051611079285.5000 - accuracy: 0.916 - ETA: 2s - loss: 2312689900148664.5000 - accuracy: 0.916 - ETA: 2s - loss: 2223740639937053.5000 - accuracy: 0.916 - ETA: 2s - loss: 2141380243935203.5000 - accuracy: 0.916 - ETA: 2s - loss: 2064902720216621.7500 - accuracy: 0.916 - ETA: 2s - loss: 1993699489716983.2500 - accuracy: 0.916 - ETA: 2s - loss: 1927243123696529.0000 - accuracy: 0.916 - ETA: 2s - loss: 1865074291368142.5000 - accuracy: 0.916 - ETA: 2s - loss: 1806791000861560.0000 - accuracy: 0.915 - ETA: 2s - loss: 1752040033597246.0000 - accuracy: 0.916 - ETA: 1s - loss: 1700509712527442.7500 - accuracy: 0.916 - ETA: 1s - loss: 1651923962460972.0000 - accuracy: 0.915 - ETA: 1s - loss: 1606037439623047.0000 - accuracy: 0.916 - ETA: 1s - loss: 1562631257888830.2500 - accuracy: 0.916 - ETA: 1s - loss: 1521509617970600.5000 - accuracy: 0.916 - ETA: 1s - loss: 1482496748544341.2500 - accuracy: 0.916 - ETA: 1s - loss: 1445434551121203.2500 - accuracy: 0.916 - ETA: 1s - loss: 1410180276393159.7500 - accuracy: 0.916 - ETA: 1s - loss: 1376604775347163.5000 - accuracy: 0.916 - ETA: 1s - loss: 1344590911230279.5000 - accuracy: 0.916 - ETA: 1s - loss: 1299267931528566.0000 - accuracy: 0.916 - ETA: 1s - loss: 1270712793515778.7500 - accuracy: 0.916 - ETA: 1s - loss: 1243385823512350.2500 - accuracy: 0.916 - ETA: 1s - loss: 1204530297759994.7500 - accuracy: 0.916 - ETA: 1s - loss: 1179948240489048.7500 - accuracy: 0.916 - ETA: 1s - loss: 1144900544948006.0000 - accuracy: 0.916 - ETA: 0s - loss: 1111874830226712.6250 - accuracy: 0.917 - ETA: 0s - loss: 1090896220569146.0000 - accuracy: 0.916 - ETA: 0s - loss: 1060871806611963.2500 - accuracy: 0.916 - ETA: 0s - loss: 1032455842542418.2500 - accuracy: 0.916 - ETA: 0s - loss: 1005522442037096.6250 - accuracy: 0.916 - ETA: 0s - loss: 979958545969707.3750 - accuracy: 0.916 - ETA: 0s - loss: 955662277716717.0000 - accuracy: 0.91 - ETA: 0s - loss: 932541630583366.2500 - accuracy: 0.91 - ETA: 0s - loss: 910513304264006.5000 - accuracy: 0.91 - ETA: 0s - loss: 889501663056415.5000 - accuracy: 0.91 - ETA: 0s - loss: 869437929117203.2500 - accuracy: 0.91 - ETA: 0s - loss: 850259342229255.5000 - accuracy: 0.91 - 5s 35ms/step - loss: 844062299392173.6250 - accuracy: 0.9161 - val_loss: 750879428661018.6250 - val_accuracy: 0.9163\n",
      "Epoch 7/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - ETA: 5s - loss: 8778687488.0000 - accuracy: 0.950 - ETA: 3s - loss: 8817522688.0000 - accuracy: 0.928 - ETA: 2s - loss: 8893815442.2857 - accuracy: 0.918 - ETA: 2s - loss: 8824931174.4000 - accuracy: 0.911 - ETA: 2s - loss: 8842821513.8462 - accuracy: 0.912 - ETA: 2s - loss: 8871860128.0000 - accuracy: 0.914 - ETA: 2s - loss: 8877816481.6842 - accuracy: 0.914 - ETA: 2s - loss: 8935767575.2727 - accuracy: 0.915 - ETA: 2s - loss: 8912303595.5200 - accuracy: 0.915 - ETA: 2s - loss: 8950489051.4286 - accuracy: 0.916 - ETA: 2s - loss: 8929916689.0667 - accuracy: 0.915 - ETA: 2s - loss: 9003174508.6061 - accuracy: 0.914 - ETA: 2s - loss: 8990690816.0000 - accuracy: 0.915 - ETA: 2s - loss: 2964984558559297.5000 - accuracy: 0.917 - ETA: 2s - loss: 2820351600235233.0000 - accuracy: 0.916 - ETA: 1s - loss: 2628055504445114.0000 - accuracy: 0.915 - ETA: 1s - loss: 2460307845024844.5000 - accuracy: 0.915 - ETA: 1s - loss: 2359887473203273.0000 - accuracy: 0.916 - ETA: 1s - loss: 2267343228398240.5000 - accuracy: 0.916 - ETA: 1s - loss: 2141380243935165.7500 - accuracy: 0.916 - ETA: 1s - loss: 2028676527650807.0000 - accuracy: 0.916 - ETA: 1s - loss: 1959908113314928.7500 - accuracy: 0.916 - ETA: 1s - loss: 1865074291368109.5000 - accuracy: 0.916 - ETA: 1s - loss: 1778994355107343.7500 - accuracy: 0.915 - ETA: 1s - loss: 1700509712527412.7500 - accuracy: 0.916 - ETA: 1s - loss: 1628657553666906.2500 - accuracy: 0.915 - ETA: 1s - loss: 1562631257888802.5000 - accuracy: 0.916 - ETA: 1s - loss: 1501749852353443.0000 - accuracy: 0.916 - ETA: 1s - loss: 1445434551121177.5000 - accuracy: 0.916 - ETA: 1s - loss: 1393190269861468.5000 - accuracy: 0.916 - ETA: 1s - loss: 1344590911230255.7500 - accuracy: 0.916 - ETA: 1s - loss: 1299267931528543.0000 - accuracy: 0.916 - ETA: 0s - loss: 1256900793011973.5000 - accuracy: 0.916 - ETA: 0s - loss: 1217209470926713.2500 - accuracy: 0.916 - ETA: 0s - loss: 1179948240489028.0000 - accuracy: 0.916 - ETA: 0s - loss: 1144900544947985.7500 - accuracy: 0.916 - ETA: 0s - loss: 1111874830226692.8750 - accuracy: 0.917 - ETA: 0s - loss: 1080701012543248.7500 - accuracy: 0.916 - ETA: 0s - loss: 1051227598426372.6250 - accuracy: 0.915 - ETA: 0s - loss: 1023319142332986.8750 - accuracy: 0.916 - ETA: 0s - loss: 996854224639470.3750 - accuracy: 0.916 - ETA: 0s - loss: 971723678640024.7500 - accuracy: 0.91 - ETA: 0s - loss: 947829050625347.1250 - accuracy: 0.91 - ETA: 0s - loss: 925081367453732.8750 - accuracy: 0.91 - ETA: 0s - loss: 903399989820620.0000 - accuracy: 0.91 - ETA: 0s - loss: 882711644652880.1250 - accuracy: 0.91 - ETA: 0s - loss: 862949651608881.6250 - accuracy: 0.91 - 4s 28ms/step - loss: 844062299392166.0000 - accuracy: 0.9161 - val_loss: 750879428661038.5000 - val_accuracy: 0.9163\n",
      "Epoch 8/20\n",
      "137/137 [==============================] - ETA: 4s - loss: 8778687488.0000 - accuracy: 0.950 - ETA: 2s - loss: 8954853580.8000 - accuracy: 0.925 - ETA: 2s - loss: 8856181134.2222 - accuracy: 0.911 - ETA: 2s - loss: 8842821435.0769 - accuracy: 0.912 - ETA: 1s - loss: 8918528873.4118 - accuracy: 0.914 - ETA: 1s - loss: 8923734912.0000 - accuracy: 0.914 - ETA: 1s - loss: 8930005205.3333 - accuracy: 0.915 - ETA: 1s - loss: 8958204397.0370 - accuracy: 0.915 - ETA: 1s - loss: 8955268723.6129 - accuracy: 0.915 - ETA: 1s - loss: 8996459549.2571 - accuracy: 0.914 - ETA: 1s - loss: 2964984558559324.0000 - accuracy: 0.917 - ETA: 1s - loss: 2753200580638756.5000 - accuracy: 0.916 - ETA: 1s - loss: 2569654468882796.0000 - accuracy: 0.915 - ETA: 1s - loss: 2359887473203273.0000 - accuracy: 0.916 - ETA: 1s - loss: 2181783455695959.0000 - accuracy: 0.916 - ETA: 1s - loss: 2064902720216603.5000 - accuracy: 0.916 - ETA: 1s - loss: 1927243123696529.0000 - accuracy: 0.916 - ETA: 1s - loss: 1835470075885137.2500 - accuracy: 0.916 - ETA: 1s - loss: 1725890321765307.2500 - accuracy: 0.916 - ETA: 1s - loss: 1651923962460972.0000 - accuracy: 0.915 - ETA: 1s - loss: 1584037047729846.2500 - accuracy: 0.916 - ETA: 0s - loss: 1521509617970600.5000 - accuracy: 0.916 - ETA: 0s - loss: 1463731077244487.2500 - accuracy: 0.916 - ETA: 0s - loss: 1410180276393159.7500 - accuracy: 0.916 - ETA: 0s - loss: 1344590911230279.5000 - accuracy: 0.916 - ETA: 0s - loss: 1299267931528566.0000 - accuracy: 0.916 - ETA: 0s - loss: 1256900793011995.7500 - accuracy: 0.917 - ETA: 0s - loss: 1217209470926734.7500 - accuracy: 0.916 - ETA: 0s - loss: 1168029660067276.2500 - accuracy: 0.916 - ETA: 0s - loss: 1133676117342855.5000 - accuracy: 0.916 - ETA: 0s - loss: 1090896220569146.0000 - accuracy: 0.917 - ETA: 0s - loss: 1051227598426391.2500 - accuracy: 0.915 - ETA: 0s - loss: 1014342738960402.0000 - accuracy: 0.916 - ETA: 0s - loss: 979958545969698.7500 - accuracy: 0.916 - ETA: 0s - loss: 955662277716708.5000 - accuracy: 0.91 - ETA: 0s - loss: 932541630583357.8750 - accuracy: 0.91 - ETA: 0s - loss: 910513304263998.5000 - accuracy: 0.91 - ETA: 0s - loss: 889501663056407.6250 - accuracy: 0.91 - ETA: 0s - loss: 869437929117195.5000 - accuracy: 0.91 - ETA: 0s - loss: 850259342229248.0000 - accuracy: 0.91 - 4s 26ms/step - loss: 844062299392166.0000 - accuracy: 0.9163 - val_loss: 750879428661021.8750 - val_accuracy: 0.9168\n",
      "Epoch 9/20\n",
      "137/137 [==============================] - ETA: 6s - loss: 8778687488.0000 - accuracy: 0.950 - ETA: 3s - loss: 8817522688.0000 - accuracy: 0.928 - ETA: 2s - loss: 8893815296.0000 - accuracy: 0.919 - ETA: 2s - loss: 8824931072.0000 - accuracy: 0.912 - ETA: 2s - loss: 8842821435.0769 - accuracy: 0.913 - ETA: 2s - loss: 8871860064.0000 - accuracy: 0.914 - ETA: 2s - loss: 8877816481.6842 - accuracy: 0.915 - ETA: 2s - loss: 8952715642.4348 - accuracy: 0.915 - ETA: 2s - loss: 8958204397.0370 - accuracy: 0.916 - ETA: 1s - loss: 8929916689.0667 - accuracy: 0.915 - ETA: 1s - loss: 8999560342.5882 - accuracy: 0.915 - ETA: 1s - loss: 3043010253085130.0000 - accuracy: 0.918 - ETA: 1s - loss: 2753200580638756.5000 - accuracy: 0.917 - ETA: 1s - loss: 2569654468882796.0000 - accuracy: 0.916 - ETA: 1s - loss: 2409051611079264.0000 - accuracy: 0.916 - ETA: 1s - loss: 2267343228398240.5000 - accuracy: 0.916 - ETA: 1s - loss: 2141380243935184.5000 - accuracy: 0.916 - ETA: 1s - loss: 2028676527650825.0000 - accuracy: 0.916 - ETA: 1s - loss: 1895649127027737.2500 - accuracy: 0.917 - ETA: 1s - loss: 1806791000861560.0000 - accuracy: 0.916 - ETA: 1s - loss: 1700509712527442.7500 - accuracy: 0.916 - ETA: 1s - loss: 1606037439623061.2500 - accuracy: 0.916 - ETA: 1s - loss: 1541796297475788.7500 - accuracy: 0.916 - ETA: 1s - loss: 1482496748544354.5000 - accuracy: 0.916 - ETA: 0s - loss: 1427589799982965.0000 - accuracy: 0.917 - ETA: 0s - loss: 1376604775347187.7500 - accuracy: 0.917 - ETA: 0s - loss: 1329135945088335.5000 - accuracy: 0.917 - ETA: 0s - loss: 1284831725064448.0000 - accuracy: 0.917 - ETA: 0s - loss: 1230158410963036.5000 - accuracy: 0.918 - ETA: 0s - loss: 1192112556008580.0000 - accuracy: 0.918 - ETA: 0s - loss: 1168029660067297.0000 - accuracy: 0.918 - ETA: 0s - loss: 1133676117342875.5000 - accuracy: 0.918 - ETA: 0s - loss: 1101285628710965.6250 - accuracy: 0.918 - ETA: 0s - loss: 1070694605243534.2500 - accuracy: 0.917 - ETA: 0s - loss: 1041757162465981.1250 - accuracy: 0.917 - ETA: 0s - loss: 1014342738960419.8750 - accuracy: 0.918 - ETA: 0s - loss: 988334178199324.5000 - accuracy: 0.918 - ETA: 0s - loss: 955662277716725.3750 - accuracy: 0.91 - ETA: 0s - loss: 925081367453757.5000 - accuracy: 0.91 - ETA: 0s - loss: 896396953225120.7500 - accuracy: 0.91 - ETA: 0s - loss: 869437929117211.0000 - accuracy: 0.91 - 3s 24ms/step - loss: 844062299392181.0000 - accuracy: 0.9182 - val_loss: 750879428661028.6250 - val_accuracy: 0.9197\n",
      "Epoch 10/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - ETA: 4s - loss: 8778687488.0000 - accuracy: 0.950 - ETA: 2s - loss: 8954853376.0000 - accuracy: 0.930 - ETA: 1s - loss: 8856181020.4444 - accuracy: 0.915 - ETA: 1s - loss: 8842821356.3077 - accuracy: 0.917 - ETA: 1s - loss: 8918528813.1765 - accuracy: 0.917 - ETA: 1s - loss: 8947017801.1429 - accuracy: 0.918 - ETA: 1s - loss: 8912303554.5600 - accuracy: 0.918 - ETA: 1s - loss: 8937542373.5172 - accuracy: 0.920 - ETA: 1s - loss: 8992137440.0000 - accuracy: 0.919 - ETA: 1s - loss: 8996459520.0000 - accuracy: 0.918 - ETA: 1s - loss: 2964984558559297.5000 - accuracy: 0.920 - ETA: 1s - loss: 2689172874669449.0000 - accuracy: 0.918 - ETA: 1s - loss: 2460307845024844.5000 - accuracy: 0.918 - ETA: 1s - loss: 2267343228398240.5000 - accuracy: 0.919 - ETA: 1s - loss: 2102446231719740.5000 - accuracy: 0.919 - ETA: 1s - loss: 1959908113314963.5000 - accuracy: 0.919 - ETA: 1s - loss: 1835470075885169.7500 - accuracy: 0.919 - ETA: 1s - loss: 1725890321765337.7500 - accuracy: 0.919 - ETA: 0s - loss: 1628657553666963.7500 - accuracy: 0.918 - ETA: 0s - loss: 1541796297475802.5000 - accuracy: 0.919 - ETA: 0s - loss: 1463731077244513.2500 - accuracy: 0.919 - ETA: 0s - loss: 1393190269861530.2500 - accuracy: 0.919 - ETA: 0s - loss: 1329135945088347.2500 - accuracy: 0.919 - ETA: 0s - loss: 1270712793515812.5000 - accuracy: 0.919 - ETA: 0s - loss: 1217209470926767.2500 - accuracy: 0.919 - ETA: 0s - loss: 1168029660067307.2500 - accuracy: 0.919 - ETA: 0s - loss: 1144900544948036.5000 - accuracy: 0.919 - ETA: 0s - loss: 1111874830226742.1250 - accuracy: 0.920 - ETA: 0s - loss: 1070694605243543.7500 - accuracy: 0.919 - ETA: 0s - loss: 1032455842542445.7500 - accuracy: 0.919 - ETA: 0s - loss: 1005522442037123.3750 - accuracy: 0.919 - ETA: 0s - loss: 988334178199342.0000 - accuracy: 0.919 - ETA: 0s - loss: 963626050910391.5000 - accuracy: 0.91 - ETA: 0s - loss: 940123201691111.0000 - accuracy: 0.92 - ETA: 0s - loss: 917739522740528.7500 - accuracy: 0.92 - ETA: 0s - loss: 896396953225136.6250 - accuracy: 0.91 - ETA: 0s - loss: 869437929117226.3750 - accuracy: 0.91 - 3s 22ms/step - loss: 844062299392196.0000 - accuracy: 0.9194 - val_loss: 750879428661045.2500 - val_accuracy: 0.9197\n",
      "Epoch 11/20\n",
      "137/137 [==============================] - ETA: 4s - loss: 8778687488.0000 - accuracy: 0.950 - ETA: 2s - loss: 8954853376.0000 - accuracy: 0.930 - ETA: 1s - loss: 8856181020.4444 - accuracy: 0.915 - ETA: 1s - loss: 8866786413.7143 - accuracy: 0.916 - ETA: 1s - loss: 8877816427.7895 - accuracy: 0.917 - ETA: 1s - loss: 8930005162.6667 - accuracy: 0.917 - ETA: 1s - loss: 8937542373.5172 - accuracy: 0.920 - ETA: 1s - loss: 8999560312.4706 - accuracy: 0.918 - ETA: 1s - loss: 2964984558559297.5000 - accuracy: 0.920 - ETA: 1s - loss: 2628055504445114.0000 - accuracy: 0.918 - ETA: 1s - loss: 2359887473203273.0000 - accuracy: 0.918 - ETA: 1s - loss: 2141380243935184.5000 - accuracy: 0.918 - ETA: 0s - loss: 1993699489717000.7500 - accuracy: 0.919 - ETA: 0s - loss: 1865074291368159.0000 - accuracy: 0.920 - ETA: 0s - loss: 1752040033597261.5000 - accuracy: 0.918 - ETA: 0s - loss: 1628657553666963.7500 - accuracy: 0.918 - ETA: 0s - loss: 1541796297475802.5000 - accuracy: 0.919 - ETA: 0s - loss: 1463731077244513.2500 - accuracy: 0.919 - ETA: 0s - loss: 1376604775347200.0000 - accuracy: 0.919 - ETA: 0s - loss: 1314032235033815.2500 - accuracy: 0.919 - ETA: 0s - loss: 1256900793012029.2500 - accuracy: 0.920 - ETA: 0s - loss: 1204530297760026.7500 - accuracy: 0.919 - ETA: 0s - loss: 1156349452001797.0000 - accuracy: 0.919 - ETA: 0s - loss: 1111874830226742.1250 - accuracy: 0.920 - ETA: 0s - loss: 1070694605243543.7500 - accuracy: 0.919 - ETA: 0s - loss: 1032455842542445.7500 - accuracy: 0.919 - ETA: 0s - loss: 996854224639514.5000 - accuracy: 0.919 - ETA: 0s - loss: 955662277716742.3750 - accuracy: 0.92 - ETA: 0s - loss: 925081367453773.8750 - accuracy: 0.92 - ETA: 0s - loss: 896396953225136.6250 - accuracy: 0.91 - ETA: 0s - loss: 869437929117226.3750 - accuracy: 0.91 - 3s 19ms/step - loss: 844062299392196.0000 - accuracy: 0.9194 - val_loss: 750879428661038.5000 - val_accuracy: 0.9197\n",
      "Epoch 12/20\n",
      "137/137 [==============================] - ETA: 3s - loss: 8778687488.0000 - accuracy: 0.950 - ETA: 1s - loss: 8883770453.3333 - accuracy: 0.925 - ETA: 1s - loss: 8824930969.6000 - accuracy: 0.915 - ETA: 1s - loss: 8866786413.7143 - accuracy: 0.916 - ETA: 1s - loss: 8877816427.7895 - accuracy: 0.917 - ETA: 1s - loss: 8952715642.4348 - accuracy: 0.918 - ETA: 1s - loss: 8950489051.4286 - accuracy: 0.919 - ETA: 1s - loss: 8992137472.0000 - accuracy: 0.919 - ETA: 1s - loss: 8980324268.9730 - accuracy: 0.919 - ETA: 1s - loss: 2753200580638781.0000 - accuracy: 0.919 - ETA: 1s - loss: 2460307845024866.0000 - accuracy: 0.918 - ETA: 1s - loss: 2223740639937053.5000 - accuracy: 0.918 - ETA: 0s - loss: 2028676527650861.0000 - accuracy: 0.919 - ETA: 0s - loss: 1865074291368175.5000 - accuracy: 0.920 - ETA: 0s - loss: 1725890321765353.0000 - accuracy: 0.919 - ETA: 0s - loss: 1628657553666978.2500 - accuracy: 0.918 - ETA: 0s - loss: 1541796297475816.0000 - accuracy: 0.919 - ETA: 0s - loss: 1463731077244526.2500 - accuracy: 0.919 - ETA: 0s - loss: 1393190269861542.5000 - accuracy: 0.919 - ETA: 0s - loss: 1314032235033827.0000 - accuracy: 0.919 - ETA: 0s - loss: 1243385823512394.2500 - accuracy: 0.919 - ETA: 0s - loss: 1192112556008601.0000 - accuracy: 0.919 - ETA: 0s - loss: 1144900544948046.5000 - accuracy: 0.919 - ETA: 0s - loss: 1101285628710985.1250 - accuracy: 0.920 - ETA: 0s - loss: 1060871806612000.8750 - accuracy: 0.919 - ETA: 0s - loss: 1023319142333041.2500 - accuracy: 0.919 - ETA: 0s - loss: 979958545969742.1250 - accuracy: 0.919 - ETA: 0s - loss: 940123201691119.3750 - accuracy: 0.92 - ETA: 0s - loss: 903399989820668.0000 - accuracy: 0.91 - ETA: 0s - loss: 876024507275861.3750 - accuracy: 0.91 - 3s 19ms/step - loss: 844062299392203.3750 - accuracy: 0.9194 - val_loss: 750879428661061.8750 - val_accuracy: 0.9197\n",
      "Epoch 13/20\n",
      "137/137 [==============================] - ETA: 3s - loss: 8778687488.0000 - accuracy: 0.950 - ETA: 1s - loss: 8883770453.3333 - accuracy: 0.925 - ETA: 1s - loss: 8804013661.0909 - accuracy: 0.914 - ETA: 1s - loss: 8848844834.1333 - accuracy: 0.918 - ETA: 1s - loss: 8877816427.7895 - accuracy: 0.917 - ETA: 1s - loss: 8952715642.4348 - accuracy: 0.918 - ETA: 1s - loss: 8958204397.0370 - accuracy: 0.919 - ETA: 1s - loss: 8955268723.6129 - accuracy: 0.918 - ETA: 1s - loss: 8996459549.2571 - accuracy: 0.918 - ETA: 1s - loss: 3043010253085130.0000 - accuracy: 0.920 - ETA: 1s - loss: 2890860155679424.0000 - accuracy: 0.920 - ETA: 1s - loss: 2689172874669472.5000 - accuracy: 0.918 - ETA: 1s - loss: 2460307845024866.0000 - accuracy: 0.918 - ETA: 1s - loss: 2312689900148664.5000 - accuracy: 0.919 - ETA: 1s - loss: 2223740639937053.5000 - accuracy: 0.918 - ETA: 1s - loss: 2102446231719759.2500 - accuracy: 0.919 - ETA: 1s - loss: 1959908113314981.0000 - accuracy: 0.919 - ETA: 1s - loss: 1835470075885186.0000 - accuracy: 0.919 - ETA: 1s - loss: 1700509712527473.0000 - accuracy: 0.919 - ETA: 0s - loss: 1584037047729888.5000 - accuracy: 0.919 - ETA: 0s - loss: 1501749852353509.5000 - accuracy: 0.919 - ETA: 0s - loss: 1410180276393209.7500 - accuracy: 0.919 - ETA: 0s - loss: 1329135945088359.0000 - accuracy: 0.919 - ETA: 0s - loss: 1256900793012040.2500 - accuracy: 0.920 - ETA: 0s - loss: 1192112556008601.0000 - accuracy: 0.919 - ETA: 0s - loss: 1133676117342895.7500 - accuracy: 0.919 - ETA: 0s - loss: 1080701012543306.1250 - accuracy: 0.919 - ETA: 0s - loss: 1032455842542454.8750 - accuracy: 0.919 - ETA: 0s - loss: 988334178199350.7500 - accuracy: 0.919 - ETA: 0s - loss: 947829050625397.5000 - accuracy: 0.92 - ETA: 0s - loss: 910513304264038.7500 - accuracy: 0.91 - ETA: 0s - loss: 876024507275861.3750 - accuracy: 0.91 - 3s 19ms/step - loss: 844062299392203.3750 - accuracy: 0.9194 - val_loss: 750879428661055.1250 - val_accuracy: 0.9197\n",
      "Epoch 14/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - ETA: 3s - loss: 8778687488.0000 - accuracy: 0.950 - ETA: 1s - loss: 8883770453.3333 - accuracy: 0.925 - ETA: 1s - loss: 8824930969.6000 - accuracy: 0.915 - ETA: 1s - loss: 8842821356.3077 - accuracy: 0.917 - ETA: 1s - loss: 8918528813.1765 - accuracy: 0.917 - ETA: 1s - loss: 8947017801.1429 - accuracy: 0.918 - ETA: 1s - loss: 8943047246.7692 - accuracy: 0.919 - ETA: 1s - loss: 8937542408.8276 - accuracy: 0.920 - ETA: 1s - loss: 9003174508.6061 - accuracy: 0.918 - ETA: 1s - loss: 8990690816.0000 - accuracy: 0.918 - ETA: 1s - loss: 2890860155679424.0000 - accuracy: 0.920 - ETA: 1s - loss: 2753200580638781.0000 - accuracy: 0.919 - ETA: 1s - loss: 2513792618183368.5000 - accuracy: 0.918 - ETA: 1s - loss: 2312689900148664.5000 - accuracy: 0.919 - ETA: 1s - loss: 2223740639937053.5000 - accuracy: 0.918 - ETA: 1s - loss: 2141380243935203.5000 - accuracy: 0.918 - ETA: 1s - loss: 2028676527650861.0000 - accuracy: 0.919 - ETA: 1s - loss: 1895649127027770.7500 - accuracy: 0.920 - ETA: 1s - loss: 1806791000861592.0000 - accuracy: 0.919 - ETA: 1s - loss: 1752040033597277.0000 - accuracy: 0.919 - ETA: 1s - loss: 1675864763202448.7500 - accuracy: 0.919 - ETA: 1s - loss: 1628657553666978.2500 - accuracy: 0.919 - ETA: 1s - loss: 1584037047729888.5000 - accuracy: 0.919 - ETA: 1s - loss: 1501749852353509.5000 - accuracy: 0.919 - ETA: 0s - loss: 1427589799982990.2500 - accuracy: 0.919 - ETA: 0s - loss: 1376604775347212.2500 - accuracy: 0.919 - ETA: 0s - loss: 1329135945088359.0000 - accuracy: 0.919 - ETA: 0s - loss: 1284831725064470.7500 - accuracy: 0.919 - ETA: 0s - loss: 1230158410963058.5000 - accuracy: 0.920 - ETA: 0s - loss: 1192112556008601.0000 - accuracy: 0.919 - ETA: 0s - loss: 1156349452001807.2500 - accuracy: 0.919 - ETA: 0s - loss: 1133676117342895.7500 - accuracy: 0.919 - ETA: 0s - loss: 1090896220569184.6250 - accuracy: 0.920 - ETA: 0s - loss: 1060871806612000.8750 - accuracy: 0.919 - ETA: 0s - loss: 1032455842542454.8750 - accuracy: 0.919 - ETA: 0s - loss: 996854224639523.2500 - accuracy: 0.919 - ETA: 0s - loss: 971723678640076.3750 - accuracy: 0.91 - ETA: 0s - loss: 940123201691119.3750 - accuracy: 0.92 - ETA: 0s - loss: 910513304264038.7500 - accuracy: 0.92 - ETA: 0s - loss: 882711644652927.0000 - accuracy: 0.91 - ETA: 0s - loss: 856557496207208.2500 - accuracy: 0.91 - 3s 25ms/step - loss: 844062299392203.3750 - accuracy: 0.9195 - val_loss: 750879428661055.1250 - val_accuracy: 0.9197\n",
      "Epoch 15/20\n",
      "137/137 [==============================] - ETA: 3s - loss: 8778687488.0000 - accuracy: 0.950 - ETA: 1s - loss: 8883770453.3333 - accuracy: 0.926 - ETA: 1s - loss: 8804013661.0909 - accuracy: 0.915 - ETA: 1s - loss: 8871860000.0000 - accuracy: 0.918 - ETA: 1s - loss: 8923734860.8000 - accuracy: 0.918 - ETA: 1s - loss: 8912303595.5200 - accuracy: 0.919 - ETA: 1s - loss: 8937542408.8276 - accuracy: 0.920 - ETA: 1s - loss: 9003174508.6061 - accuracy: 0.918 - ETA: 1s - loss: 3043010253085130.0000 - accuracy: 0.921 - ETA: 1s - loss: 2689172874669472.5000 - accuracy: 0.918 - ETA: 1s - loss: 2409051611079285.5000 - accuracy: 0.919 - ETA: 1s - loss: 2223740639937053.5000 - accuracy: 0.919 - ETA: 1s - loss: 2028676527650861.0000 - accuracy: 0.919 - ETA: 0s - loss: 1865074291368175.5000 - accuracy: 0.920 - ETA: 0s - loss: 1725890321765353.0000 - accuracy: 0.919 - ETA: 0s - loss: 1606037439623089.7500 - accuracy: 0.919 - ETA: 0s - loss: 1501749852353496.0000 - accuracy: 0.919 - ETA: 0s - loss: 1410180276393197.2500 - accuracy: 0.919 - ETA: 0s - loss: 1329135945088347.2500 - accuracy: 0.919 - ETA: 0s - loss: 1256900793012029.2500 - accuracy: 0.920 - ETA: 0s - loss: 1192112556008590.5000 - accuracy: 0.919 - ETA: 0s - loss: 1133676117342885.7500 - accuracy: 0.920 - ETA: 0s - loss: 1080701012543296.6250 - accuracy: 0.919 - ETA: 0s - loss: 1032455842542445.7500 - accuracy: 0.919 - ETA: 0s - loss: 988334178199342.0000 - accuracy: 0.919 - ETA: 0s - loss: 947829050625389.1250 - accuracy: 0.92 - ETA: 0s - loss: 910513304264030.7500 - accuracy: 0.92 - ETA: 0s - loss: 876024507275853.6250 - accuracy: 0.92 - 2s 17ms/step - loss: 844062299392196.0000 - accuracy: 0.9196 - val_loss: 750879428661061.8750 - val_accuracy: 0.9197\n",
      "Epoch 16/20\n",
      "137/137 [==============================] - ETA: 2s - loss: 8778687488.0000 - accuracy: 0.950 - ETA: 1s - loss: 8883770453.3333 - accuracy: 0.926 - ETA: 1s - loss: 8804013661.0909 - accuracy: 0.915 - ETA: 1s - loss: 8871860000.0000 - accuracy: 0.918 - ETA: 1s - loss: 8923734860.8000 - accuracy: 0.918 - ETA: 1s - loss: 8912303595.5200 - accuracy: 0.919 - ETA: 1s - loss: 8929916689.0667 - accuracy: 0.919 - ETA: 1s - loss: 8996459578.5143 - accuracy: 0.918 - ETA: 1s - loss: 2890860155679449.5000 - accuracy: 0.920 - ETA: 1s - loss: 2569654468882841.5000 - accuracy: 0.918 - ETA: 1s - loss: 2312689900148685.0000 - accuracy: 0.919 - ETA: 0s - loss: 2102446231719777.7500 - accuracy: 0.919 - ETA: 0s - loss: 1927243123696580.2500 - accuracy: 0.920 - ETA: 0s - loss: 1778994355107422.5000 - accuracy: 0.918 - ETA: 0s - loss: 1651923962461030.5000 - accuracy: 0.919 - ETA: 0s - loss: 1541796297475816.0000 - accuracy: 0.919 - ETA: 0s - loss: 1445434551121241.5000 - accuracy: 0.919 - ETA: 0s - loss: 1360409529015079.2500 - accuracy: 0.919 - ETA: 0s - loss: 1299267931528612.0000 - accuracy: 0.919 - ETA: 0s - loss: 1243385823512394.2500 - accuracy: 0.920 - ETA: 0s - loss: 1192112556008601.0000 - accuracy: 0.919 - ETA: 0s - loss: 1144900544948046.5000 - accuracy: 0.920 - ETA: 0s - loss: 1101285628710985.1250 - accuracy: 0.920 - ETA: 0s - loss: 1051227598426428.5000 - accuracy: 0.919 - ETA: 0s - loss: 1005522442037132.2500 - accuracy: 0.919 - ETA: 0s - loss: 963626050910400.0000 - accuracy: 0.920 - ETA: 0s - loss: 932541630583399.2500 - accuracy: 0.92 - ETA: 0s - loss: 903399989820668.0000 - accuracy: 0.91 - ETA: 0s - loss: 876024507275861.3750 - accuracy: 0.92 - 2s 18ms/step - loss: 844062299392203.3750 - accuracy: 0.9196 - val_loss: 750879428661048.5000 - val_accuracy: 0.9197\n",
      "Epoch 17/20\n",
      "137/137 [==============================] - ETA: 2s - loss: 8778687488.0000 - accuracy: 0.950 - ETA: 1s - loss: 8883770453.3333 - accuracy: 0.926 - ETA: 1s - loss: 8804013661.0909 - accuracy: 0.915 - ETA: 1s - loss: 8871860000.0000 - accuracy: 0.918 - ETA: 1s - loss: 8947017801.1429 - accuracy: 0.918 - ETA: 1s - loss: 8943047246.7692 - accuracy: 0.919 - ETA: 1s - loss: 8955268723.6129 - accuracy: 0.919 - ETA: 1s - loss: 8990690844.4444 - accuracy: 0.919 - ETA: 1s - loss: 2820351600235282.5000 - accuracy: 0.920 - ETA: 1s - loss: 2513792618183390.5000 - accuracy: 0.918 - ETA: 1s - loss: 2312689900148685.0000 - accuracy: 0.919 - ETA: 0s - loss: 2102446231719777.7500 - accuracy: 0.919 - ETA: 0s - loss: 1927243123696580.2500 - accuracy: 0.920 - ETA: 0s - loss: 1778994355107422.5000 - accuracy: 0.918 - ETA: 0s - loss: 1651923962461030.5000 - accuracy: 0.919 - ETA: 0s - loss: 1541796297475816.0000 - accuracy: 0.919 - ETA: 0s - loss: 1445434551121241.5000 - accuracy: 0.919 - ETA: 0s - loss: 1360409529015079.2500 - accuracy: 0.919 - ETA: 0s - loss: 1284831725064470.7500 - accuracy: 0.919 - ETA: 0s - loss: 1217209470926778.0000 - accuracy: 0.919 - ETA: 0s - loss: 1156349452001807.2500 - accuracy: 0.919 - ETA: 0s - loss: 1101285628710985.1250 - accuracy: 0.920 - ETA: 0s - loss: 1051227598426428.5000 - accuracy: 0.919 - ETA: 0s - loss: 1005522442037132.2500 - accuracy: 0.919 - ETA: 0s - loss: 963626050910400.0000 - accuracy: 0.920 - ETA: 0s - loss: 925081367453782.0000 - accuracy: 0.92 - ETA: 0s - loss: 889501663056447.0000 - accuracy: 0.91 - ETA: 0s - loss: 856557496207208.2500 - accuracy: 0.91 - 2s 17ms/step - loss: 844062299392203.3750 - accuracy: 0.9196 - val_loss: 750879428661041.8750 - val_accuracy: 0.9197\n",
      "Epoch 18/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "137/137 [==============================] - ETA: 3s - loss: 8778687488.0000 - accuracy: 0.950 - ETA: 2s - loss: 8954853376.0000 - accuracy: 0.931 - ETA: 1s - loss: 8824930969.6000 - accuracy: 0.916 - ETA: 1s - loss: 8848844834.1333 - accuracy: 0.918 - ETA: 1s - loss: 8923734860.8000 - accuracy: 0.918 - ETA: 1s - loss: 8912303595.5200 - accuracy: 0.919 - ETA: 1s - loss: 8929916689.0667 - accuracy: 0.919 - ETA: 1s - loss: 8999560372.7059 - accuracy: 0.919 - ETA: 1s - loss: 2964984558559350.0000 - accuracy: 0.920 - ETA: 1s - loss: 2628055504445160.5000 - accuracy: 0.918 - ETA: 1s - loss: 2359887473203315.0000 - accuracy: 0.919 - ETA: 1s - loss: 2223740639937073.2500 - accuracy: 0.919 - ETA: 1s - loss: 2064902720216640.0000 - accuracy: 0.919 - ETA: 0s - loss: 1927243123696580.2500 - accuracy: 0.920 - ETA: 0s - loss: 1806791000861608.0000 - accuracy: 0.919 - ETA: 0s - loss: 1675864763202463.5000 - accuracy: 0.919 - ETA: 0s - loss: 1562631257888885.5000 - accuracy: 0.919 - ETA: 0s - loss: 1463731077244526.2500 - accuracy: 0.919 - ETA: 0s - loss: 1376604775347212.2500 - accuracy: 0.919 - ETA: 0s - loss: 1299267931528612.0000 - accuracy: 0.919 - ETA: 0s - loss: 1230158410963058.5000 - accuracy: 0.920 - ETA: 0s - loss: 1168029660067317.7500 - accuracy: 0.920 - ETA: 0s - loss: 1111874830226752.0000 - accuracy: 0.920 - ETA: 0s - loss: 1060871806612000.8750 - accuracy: 0.919 - ETA: 0s - loss: 1014342738960437.8750 - accuracy: 0.919 - ETA: 0s - loss: 971723678640076.3750 - accuracy: 0.919 - ETA: 0s - loss: 932541630583399.2500 - accuracy: 0.92 - ETA: 0s - loss: 896396953225144.5000 - accuracy: 0.91 - ETA: 0s - loss: 862949651608919.8750 - accuracy: 0.91 - 2s 18ms/step - loss: 844062299392203.3750 - accuracy: 0.9196 - val_loss: 750879428661048.5000 - val_accuracy: 0.9198\n",
      "Epoch 19/20\n",
      "137/137 [==============================] - ETA: 3s - loss: 8778687488.0000 - accuracy: 0.950 - ETA: 1s - loss: 8883770453.3333 - accuracy: 0.926 - ETA: 1s - loss: 8804013661.0909 - accuracy: 0.915 - ETA: 1s - loss: 8871860000.0000 - accuracy: 0.918 - ETA: 1s - loss: 8947017801.1429 - accuracy: 0.918 - ETA: 1s - loss: 8943047246.7692 - accuracy: 0.919 - ETA: 1s - loss: 8955268723.6129 - accuracy: 0.919 - ETA: 1s - loss: 8990690844.4444 - accuracy: 0.919 - ETA: 1s - loss: 2820351600235282.5000 - accuracy: 0.920 - ETA: 0s - loss: 2460307845024888.0000 - accuracy: 0.919 - ETA: 0s - loss: 2181783455695997.5000 - accuracy: 0.919 - ETA: 0s - loss: 1993699489717036.2500 - accuracy: 0.920 - ETA: 0s - loss: 1835470075885202.2500 - accuracy: 0.919 - ETA: 0s - loss: 1700509712527488.0000 - accuracy: 0.919 - ETA: 0s - loss: 1584037047729902.5000 - accuracy: 0.919 - ETA: 0s - loss: 1482496748544380.7500 - accuracy: 0.919 - ETA: 0s - loss: 1393190269861542.5000 - accuracy: 0.919 - ETA: 0s - loss: 1314032235033827.0000 - accuracy: 0.919 - ETA: 0s - loss: 1243385823512394.2500 - accuracy: 0.920 - ETA: 0s - loss: 1179948240489090.5000 - accuracy: 0.920 - ETA: 0s - loss: 1122669642155649.2500 - accuracy: 0.920 - ETA: 0s - loss: 1070694605243553.1250 - accuracy: 0.919 - ETA: 0s - loss: 1023319142333041.2500 - accuracy: 0.919 - ETA: 0s - loss: 979958545969742.1250 - accuracy: 0.919 - ETA: 0s - loss: 940123201691119.3750 - accuracy: 0.92 - ETA: 0s - loss: 903399989820668.0000 - accuracy: 0.91 - ETA: 0s - loss: 869437929117234.0000 - accuracy: 0.92 - 2s 17ms/step - loss: 844062299392203.3750 - accuracy: 0.9197 - val_loss: 750879428661041.8750 - val_accuracy: 0.9198\n",
      "Epoch 20/20\n",
      "137/137 [==============================] - ETA: 3s - loss: 8778687488.0000 - accuracy: 0.950 - ETA: 1s - loss: 8883770453.3333 - accuracy: 0.926 - ETA: 1s - loss: 8824930969.6000 - accuracy: 0.916 - ETA: 1s - loss: 8848844834.1333 - accuracy: 0.918 - ETA: 1s - loss: 8923734860.8000 - accuracy: 0.918 - ETA: 1s - loss: 8912303616.0000 - accuracy: 0.919 - ETA: 1s - loss: 8929916706.1333 - accuracy: 0.919 - ETA: 1s - loss: 8996459593.1429 - accuracy: 0.918 - ETA: 1s - loss: 2890860155679462.5000 - accuracy: 0.920 - ETA: 1s - loss: 2569654468882853.0000 - accuracy: 0.919 - ETA: 1s - loss: 2312689900148695.0000 - accuracy: 0.919 - ETA: 0s - loss: 2102446231719768.5000 - accuracy: 0.919 - ETA: 0s - loss: 1927243123696571.7500 - accuracy: 0.920 - ETA: 0s - loss: 1778994355107414.7500 - accuracy: 0.919 - ETA: 0s - loss: 1651923962461023.0000 - accuracy: 0.919 - ETA: 0s - loss: 1541796297475809.2500 - accuracy: 0.919 - ETA: 0s - loss: 1445434551121235.2500 - accuracy: 0.919 - ETA: 0s - loss: 1360409529015073.2500 - accuracy: 0.920 - ETA: 0s - loss: 1284831725064465.0000 - accuracy: 0.919 - ETA: 0s - loss: 1217209470926772.5000 - accuracy: 0.919 - ETA: 0s - loss: 1156349452001802.2500 - accuracy: 0.920 - ETA: 0s - loss: 1101285628710980.2500 - accuracy: 0.920 - ETA: 0s - loss: 1051227598426423.8750 - accuracy: 0.919 - ETA: 0s - loss: 1005522442037127.7500 - accuracy: 0.920 - ETA: 0s - loss: 963626050910395.7500 - accuracy: 0.920 - ETA: 0s - loss: 932541630583395.1250 - accuracy: 0.92 - ETA: 0s - loss: 903399989820664.0000 - accuracy: 0.92 - ETA: 0s - loss: 876024507275857.5000 - accuracy: 0.92 - 2s 17ms/step - loss: 844062299392199.6250 - accuracy: 0.9199 - val_loss: 750879428661048.5000 - val_accuracy: 0.9207\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x168799fac18>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NNmodel.fit(train_dataset.batch(200),\n",
    "                            epochs=20,\n",
    "                            validation_data = val_dataset.batch(200),\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 - 0s - loss: 8890656312.8889 - accuracy: 0.9204\n",
      "loss: 8890656312.889\n",
      "accuracy: 0.920\n"
     ]
    }
   ],
   "source": [
    "results = NNmodel.evaluate(test_dataset.batch(200), verbose=2)\n",
    "for name, value in zip(NNmodel.metrics_names, results):\n",
    "    print(\"%s: %.3f\" % (name, value))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
